{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from generate_sql_examples_final import get_mysql_metadata\n",
    "from mongo_examples_testing import get_mongodb_metadata\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from input_process import match_query_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_queries = {\n",
    "    (0, \"SELECT\"): \"Show me all the records in the course table\",  # Select\n",
    "    (1, \"UPLOAD\"): \"Upload this data '../data/sql_data/students.csv'\",  # Upload\n",
    "    (2, \"EXAMPLE\", \"SELECT\", \"SQL\"): \"Show me examples of sql queries\",  # Example\n",
    "    (3, \"EXAMPLE\", \"SELECT\", \"GROUP BY\", \"SQL\"): \"Show me examples of sql queries using group by\",  # Example group by\n",
    "    (4, \"SELECT\", \"WHERE\"): \"Get the details of students who work in the Calculus department\",  # Where\n",
    "    (5, \"SELECT\", \"AGGREGATE\"): \"How many employees are there in the company\",  # Select count(*)\n",
    "    (6, \"SELECT\", \"WHERE\"): \"Show me the names and salaries of employees earning more than $50000\",  # Where\n",
    "    (7, \"SELECT\", \"ORDER BY\"): \"List all employees, sorted by their hire date in descending order\",  # Order by\n",
    "    (8, \"AGGREGATE\", \"WHERE\"): \"Find the average salary of employees in the Engineering department\",  # Select Avg() where\n",
    "    (9, \"SELECT\", \"GROUP BY\"): \"How many employees are there in each department\",  # Group by\n",
    "    (10, \"SELECT\", \"HAVING\"): \"Show me the departments where the total salaries of employees exceed $100000\",  # Having\n",
    "    (11, \"SELECT\", \"HAVING\"): \"List the products where the average price is less than $50\",  # Having\n",
    "    (12, \"SELECT\", \"ORDER BY\", \"LIMIT\"): \"What are the top 10 highest paid employees\",  # Order by limit\n",
    "    (13, \"SELECT\", \"HAVING\"): \"Which customers have placed more than 5 orders\",  # Having\n",
    "    (14, \"SELECT\", \"GROUP BY\"): \"Find the total revenue generated by each product category\",  # Group by\n",
    "    (15, \"SELECT\", \"WHERE\", \"ORDER BY\"): \"List all orders placed in the last 30 days, sorted by order date\",  # Where Order by\n",
    "    (16, \"SELECT\", \"JOIN\"): \"Join the employees table with the departments table to find department names\",  # Join\n",
    "    (17, \"SELECT\", \"JOIN\"): \"List all customers and their orders\",  # Join\n",
    "    (18, \"SELECT\", \"GROUP BY\"): \"How many products are in stock for each supplier\",  # Group by\n",
    "    (19, \"SELECT\", \"WHERE\"): \"Show me the products where the stock quantity is less than 10\",  # Where\n",
    "    (20, \"UPLOAD\"): \"Upload the file '../data/new_products.json' into the database\",  # Upload\n",
    "    (21, \"GROUP BY\", \"AGGREGATE\"): \"Find the maximum salary in each department\",  # Group by Max()\n",
    "    (22, \"SELECT\", \"GROUP BY\"): \"List employees grouped by their job titles\",  # Group by\n",
    "    (23, \"SELECT\", \"WHERE\"): \"Show me all orders where the total exceeds $1000\",  # Where\n",
    "    (24, \"SELECT\", \"ORDER BY\"): \"List all customers sorted by their last purchase date\",  # Order by\n",
    "    (25, \"EXAMPLE\", \"SELECT\", \"SQL\"): \"Show me examples of sql queries for finding duplicates\",  # Example\n",
    "    (26, \"AGGREGATE\", \"WHERE\"): \"How many employees were hired in the last year\",  # Where Count()\n",
    "    (27, \"GROUP BY\", \"AGGREGATE\"): \"Find the minimum price of products in each category\",  # Group by Min()\n",
    "    (28, \"SELECT\", \"JOIN\"): \"Join the orders table with the customers table to get customer details\",  # Join\n",
    "    (29, \"SELECT\", \"WHERE\"): \"List all records in the products table where price is greater than $20\",  # Where\n",
    "    (30, \"SELECT\", \"ORDER BY\", \"LIMIT\"): \"Show me the names of employees earning the top 5 highest salaries\",  # Order by limit\n",
    "    (31, \"GROUP BY\", \"AGGREGATE\"): \"Find the sum of sales for each region\",  # Group by Sum()\n",
    "    (32, \"SELECT\", \"ORDER BY\"): \"List all products sorted by their price in ascending order\",  # Order by\n",
    "    (33, \"SELECT\", \"EXAMPLE\", \"MONGODB\"): \"Give me examples of nosql queries.\",  # Order by\n",
    "}\n",
    "\n",
    "login_info = {\n",
    "    'endpoint': \"localhost\",\n",
    "    'username': \"root\",\n",
    "    'password': \"MySQLDBP455\",\n",
    "    'sql_database_name': \"chatdb\",\n",
    "    'mongo_username': 'mdmolnar',\n",
    "    'mongo_password': 'AtM0nG0d1452',\n",
    "    'mongo_database_name': \"ChatDB\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show me all columns where food_type is burgers and city is alameda from generalinfo\n",
      "kywds ['WHERE', 'SELECT']\n",
      "['show', 'me', 'all', 'columns', 'where', 'food_type', 'is', 'burgers', 'and', 'city', 'is', 'alameda', 'from', 'generalinfo']\n",
      "Generating query for table: ['generalinfo']\n",
      "Columns in associated table: ['id_restaurant', 'label', 'food_type', 'city', 'review']\n",
      "Creating query with columns: ['food_type', 'city', '*']\n",
      "WHERE: []\n",
      "Executing query: SELECT * FROM generalinfo WHERE  ;\n",
      "Error executing query\n"
     ]
    }
   ],
   "source": [
    "aggregate_words = {\n",
    "    'MIN': ['minimum', 'smallest', 'lowest', 'least', 'min'],\n",
    "    'MAX': ['maximum', 'largest', 'highest', 'greatest', 'max'],\n",
    "    'AVG': ['average', 'mean', 'avg'],\n",
    "    'COUNT': ['count', 'number', 'total', 'many'],\n",
    "    'SUM': ['sum', 'total', 'add', 'combined']\n",
    "}\n",
    "import string\n",
    "group_words = [\"group by\", \"aggregate\", \"group\", \"grouping\", \"each\", \"total\", \"categorize\",\n",
    "                 \"partition\", \"classify\", \"segment\", \"cluster\", \"bucket\", 'grouped']\n",
    "\n",
    "where_words = {\n",
    "    'LESS_THAN': ['less', 'fewer', 'below', 'under', 'lower than', \n",
    "                  'smaller than', 'not exceeding', 'underneath', '<'],\n",
    "    'GREATER_THAN': ['more', 'greater', 'above', 'over', 'higher than', \n",
    "                     'exceeds', 'bigger than', 'larger than', '>'],\n",
    "    'EQUAL_TO': ['equal', 'exactly', 'equals', 'same as', '=',\n",
    "                 'identical to', 'matches', 'equivalent to'],\n",
    "    'NOT_EQUAL_TO': ['not equal', 'different', 'not the same as', \n",
    "                     'does not equal', 'unequal', 'not identical', '!=']\n",
    "}\n",
    "\n",
    "order_words = [\"order by\", \"sort\", \"sort by\", \"ordered\", \"order\", \"ascending\", \"descending\", \"rank\", \"arrange\", \"prioritize\",\n",
    "               \"sequence\", \"order\", \"hierarchy\", \"top\", \"bottom\", \"sorted\", 'biggest', 'smallest']\n",
    "\n",
    "desc_words = ['descending', 'desc', 'biggest to smallest', 'reverse', 'biggest']\n",
    "\n",
    "all_cols = ['all columns', 'every column', 'each column']\n",
    "\n",
    "limit_words = ['top', 'bottom', 'highest', 'lowest', 'biggest', 'smallest', 'limit', 'only', 'list']\n",
    "\n",
    "def execute_sql_query(user_input, keywords, login_info):\n",
    "    exclude = string.punctuation.translate(str.maketrans('', '', \"_()\"))\n",
    "    user_list = user_input.translate(str.maketrans('', '', exclude)).split()\n",
    "\n",
    "    print(user_list)\n",
    "    \n",
    "    mdata = get_mysql_metadata(login_info)\n",
    "\n",
    "    tables = [table for table in mdata.keys()]\n",
    "\n",
    "    assoc_tables = []\n",
    "\n",
    "    for word in user_list:\n",
    "        if word in tables:\n",
    "            assoc_tables.append(word)\n",
    "    print('Generating query for table:', assoc_tables)\n",
    "\n",
    "    assoc_cols = []\n",
    "    col_idx_mdata = []\n",
    "    for i in range(len(assoc_tables)):\n",
    "        table_columns = []\n",
    "        for j in range(len(mdata[assoc_tables[i]])):\n",
    "            table_columns.append(mdata[assoc_tables[i]][j]['name'])\n",
    "\n",
    "        print('Columns in associated table:', table_columns)\n",
    "        for word in user_list:\n",
    "            if word in table_columns:\n",
    "                assoc_cols.append(word)\n",
    "                idx = table_columns.index(word)\n",
    "                col_idx_mdata.append(idx)\n",
    "\n",
    "    unique_vals = []\n",
    "    for i in assoc_tables:\n",
    "        for j in col_idx_mdata:\n",
    "            unique_vals += mdata[i][j]['unique_values']\n",
    "\n",
    "    unique_vals = [str(item) if isinstance(item, (int, float)) else item for item in unique_vals]\n",
    "\n",
    "    for i, word in enumerate(user_list):\n",
    "        try:\n",
    "            bigram = word + f' {user_list[i+1]}'\n",
    "        except:\n",
    "            pass\n",
    "        if bigram in all_cols:\n",
    "            assoc_cols.append('*')\n",
    "    if len(assoc_cols) == 0:\n",
    "        assoc_cols.append('*')\n",
    "    print('Creating query with columns:', assoc_cols)\n",
    "\n",
    "    query = ''\n",
    "    from_in_query = False\n",
    "\n",
    "    if 'SELECT' in keywords:\n",
    "        if '*' in assoc_cols:\n",
    "            query += 'SELECT * '\n",
    "        else:\n",
    "            query += 'SELECT ' + ', '.join(assoc_cols) + ' '\n",
    "    \n",
    "    elif 'AGGREGATE' in keywords:\n",
    "        processes = []\n",
    "\n",
    "        for key, value in aggregate_words.items():\n",
    "            for i, word in enumerate(user_list):\n",
    "                if word.lower() in value:\n",
    "                    processes.append(key)\n",
    "                    if user_list[i+1] in assoc_cols:\n",
    "                        processes.append(user_list[i+1])\n",
    "                    elif user_list[i+2] in assoc_cols:\n",
    "                        processes.append(user_list[i+2])\n",
    "\n",
    "\n",
    "        if len(processes)%2 ==1:\n",
    "            processes.append('*')\n",
    "        \n",
    "        query += 'SELECT '\n",
    "\n",
    "        for key, values in aggregate_words.items():\n",
    "            if key in processes:\n",
    "                idx = processes.index(key)\n",
    "\n",
    "                if idx == len(processes)-2:\n",
    "                    query += f'{key}({processes[idx+1]})'\n",
    "                else:\n",
    "                    query += f'{key}({processes[idx+1]}), '\n",
    "                assoc_cols.append(f'{key}({processes[idx+1]})')\n",
    "\n",
    "        query += ' '\n",
    "\n",
    "    if not from_in_query:\n",
    "        query += 'FROM ' + ', '.join(assoc_tables) + ' '\n",
    "        from_in_query = True\n",
    "\n",
    "    if 'JOIN' in keywords:\n",
    "        pass\n",
    "\n",
    "    if 'WHERE' in keywords:\n",
    "        processes = []\n",
    "\n",
    "        for key, values in where_words.items():\n",
    "            for i, word in enumerate(user_list):\n",
    "                if i < len(user_list)-1:\n",
    "                    bigram = word + ' ' + user_list[i+1]\n",
    "                else:\n",
    "                    bigram = word\n",
    "        \n",
    "                if word.lower() in values:\n",
    "                    if user_list[i-1] in assoc_cols:\n",
    "                        processes.append(user_list[i-1])\n",
    "                    elif user_list[i-2] in assoc_cols:\n",
    "                        processes.append(user_list[i-2])\n",
    "                    processes.append(key)\n",
    "                    if user_list[i+1] in unique_vals:\n",
    "                        processes.append(user_list[i+1])\n",
    "                    elif user_list[i+2] in unique_vals:\n",
    "                        processes.append(user_list[i+2])\n",
    "                    elif f'{user_list[i+1]} {user_list[i+2]}' in unique_vals:\n",
    "                        processes.append(f'{user_list[i+1]} {user_list[i+2]}')\n",
    "                    elif f'{user_list[i+2]} {user_list[i+3]}' in unique_vals:\n",
    "                        processes.append(f'{user_list[i+2]} {user_list[i+3]}')\n",
    "                                       \n",
    "                elif bigram.lower() in values:\n",
    "                    if user_list[i-1] in assoc_cols:\n",
    "                        processes.append(user_list[i-1])\n",
    "                    elif user_list[i-2] in assoc_cols:\n",
    "                        processes.append(user_list[i-2])\n",
    "                    processes.append(key)\n",
    "                    if user_list[i+2] in unique_vals:\n",
    "                        processes.append(user_list[i+2])\n",
    "                    elif user_list[i+3] in unique_vals:\n",
    "                        processes.append(user_list[i+3])\n",
    "                    elif f'{user_list[i+2]} {user_list[i+3]}' in unique_vals:\n",
    "                        processes.append(f'{user_list[i+2]} {user_list[i+3]}')\n",
    "                    elif f'{user_list[i+3]} {user_list[i+4]}' in unique_vals:\n",
    "                        processes.append(f'{user_list[i+3]} {user_list[i+4]}')\n",
    "\n",
    "\n",
    "        query += 'WHERE '\n",
    "        if len(processes) > 3:\n",
    "            for idx in range(1, len(processes)//3):\n",
    "                processes.insert(idx*3, 'AND')\n",
    "        \n",
    "        print(\"WHERE:\", processes)\n",
    "\n",
    "        for process_idx in range(0, len(processes), 4):\n",
    "            try:\n",
    "                processes[process_idx+2] = int(processes[process_idx+2])\n",
    "                if processes[process_idx+1] == 'GREATER_THAN':\n",
    "                    query += f'{processes[process_idx]} > {processes[process_idx+2]}'\n",
    "                elif processes[process_idx+1] == 'LESS_THAN':\n",
    "                    query += f'{processes[process_idx]} < {processes[process_idx+2]}'\n",
    "                elif processes[process_idx+1] == 'EQUAL_TO':\n",
    "                    query += f'{processes[process_idx]} = {processes[process_idx+2]}'\n",
    "                elif processes[process_idx+1] == 'NOT_EQUAL_TO':\n",
    "                    query += f'{processes[process_idx]} != {processes[process_idx+2]}'\n",
    "            except:\n",
    "                if processes[process_idx+1] == 'GREATER_THAN':\n",
    "                    query += f'{processes[process_idx]} > {processes[process_idx+2]}'\n",
    "                elif processes[process_idx+1] == 'LESS_THAN':\n",
    "                    query += f'{processes[process_idx]} < {processes[process_idx+2]}'\n",
    "                elif processes[process_idx+1] == 'EQUAL_TO':\n",
    "                    query += f\"{processes[process_idx]} = \\'{processes[process_idx+2]}\\'\"\n",
    "                elif processes[process_idx+1] == 'NOT_EQUAL_TO':\n",
    "                    query += f\"{processes[process_idx]} != \\'{processes[process_idx+2]}\\'\"\n",
    "            try:\n",
    "                if processes[process_idx+3] == 'AND':\n",
    "                    query += ' AND '\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        query += ' '\n",
    "\n",
    "    if 'GROUP BY' in keywords:\n",
    "        group_by = []\n",
    "\n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word + f' {user_list[i+1]}'\n",
    "            except:\n",
    "                pass\n",
    "            if bigram in group_words:\n",
    "                if user_list[i+1] in assoc_cols:\n",
    "                    group_by.append(user_list[i+1])\n",
    "                elif user_list[i+2] in assoc_cols:\n",
    "                    group_by.append(user_list[i+2])\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    group_by.append(user_list[i+3])\n",
    "            elif word in group_words:\n",
    "                if user_list[i+1] in assoc_cols:\n",
    "                    group_by.append(user_list[i+1])\n",
    "                elif user_list[i+2] in assoc_cols:\n",
    "                    group_by.append(user_list[i+2])\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    group_by.append(user_list[i+3])\n",
    "        print('gb:', group_by)\n",
    "\n",
    "        for i, col in enumerate(group_by):\n",
    "            if i == 0:\n",
    "                query += f'GROUP BY {col}'\n",
    "            else:\n",
    "                query += f', {col}'\n",
    "        query += ' '\n",
    "        query = query.replace(\"SELECT\", f\"SELECT {col},\")\n",
    "    \n",
    "    if 'HAVING' in keywords:\n",
    "        pass\n",
    "    \n",
    "    if 'ORDER BY' in keywords:\n",
    "        asc = 'ASC'\n",
    "        order = []\n",
    "\n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word + f' {user_list[i+1]}'\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if bigram in order_words:\n",
    "                    if user_list[i+2] in assoc_cols:\n",
    "                        order.append(user_list[i+2])\n",
    "                    elif user_list[i+3] in assoc_cols:\n",
    "                        order.append(user_list[i+3])\n",
    "                elif word in order_words:\n",
    "                    if user_list[i+1] in assoc_cols:\n",
    "                        order.append(user_list[i+1])\n",
    "                    elif user_list[i+2] in assoc_cols:\n",
    "                        order.append(user_list[i+2])\n",
    "                    elif user_list[i+3] in assoc_cols:\n",
    "                        order.append(user_list[i+3])\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word.lower() + f' {user_list[i+1]}'.lower()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                trigram = bigram + f' {user_list[i+2]}'\n",
    "            except:\n",
    "                pass\n",
    "            if word.lower() in desc_words or bigram in desc_words or trigram in desc_words:\n",
    "                asc = 'DESC'\n",
    "\n",
    "        query += f'ORDER BY ' + ', '.join(order) + f' {asc} '\n",
    "    \n",
    "    \n",
    "    if 'LIMIT' in keywords:\n",
    "        query += 'LIMIT '\n",
    "        for i, word in enumerate(user_list):\n",
    "            if word in limit_words:\n",
    "                try:\n",
    "                    query += f'{int(user_list[i+1])}'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    query += f'{int(user_list[i+2])}'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    query += f'{int(user_list[i+3])}'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    query += f'{int(user_list[i-1])}'\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    query += ';'\n",
    "    \n",
    "    connection = pymysql.connect(\n",
    "        host = login_info['endpoint'],\n",
    "        user = login_info['username'],\n",
    "        password = login_info['password'],\n",
    "        database = login_info['sql_database_name']\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    print(\"Executing query:\", query)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        print(tabulate(rows, headers=columns, tablefmt=\"pretty\"))\n",
    "\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except:\n",
    "        print('Error executing query')\n",
    "\n",
    "    return\n",
    "\n",
    "    # print(query)\n",
    "\n",
    "user_input = 'Show me how many rows where review is greater than 1 from generalinfo'  # work on this\n",
    "user_input = 'Show me how many rows in generalinfo'\n",
    "user_input =  \"How many restaurants have each review from generalinfo\"\n",
    "# user_input = 'Show me how many rows where course_id is greater than 104 from course, sort by course_id'\n",
    "user_input = 'show me the 5 biggest street_num, filter to where city is san francisco and use the location table'\n",
    "user_input = 'show me all columns where food_type is burgers and city is alameda from generalinfo'\n",
    "user_input = \"show me average review where label is baskin robbins from generalinfo\"\n",
    "user_input = 'Show me average review where food_type is ice cream group by label from generalinfo limit 5'\n",
    "user_input = 'show me columns group by label from generalinfo'\n",
    "user_input = 'show me the biggest 5 food types by average review of restaurants from each food_type in generalinfo rank them by AVG(review)'\n",
    "user_input = 'show me all columns where food_type is burgers and city is alameda from generalinfo'\n",
    "print(user_input)\n",
    "keywords = match_query_pattern(user_input)\n",
    "print('kywds', keywords)\n",
    "\n",
    "execute_sql_query(user_input, keywords, login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SQL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sql_or_nosql(user_input, login_info):\n",
    "    decision = []\n",
    "\n",
    "    user_list = user_input.replace(\",\", \"\").split()\n",
    "\n",
    "    sql_mdata = get_mysql_metadata(login_info)\n",
    "    mongo_mdata = get_mongodb_metadata(login_info)\n",
    "\n",
    "    for word in user_list:\n",
    "        if word in sql_mdata.keys():\n",
    "            decision.append(1)\n",
    "        elif word in mongo_mdata.keys():\n",
    "            decision.append(0)\n",
    "\n",
    "    if np.mean(decision) > 0.5:\n",
    "        return 'SQL'\n",
    "    elif len(decision) > 0:\n",
    "        return'MONGODB'\n",
    "    else:\n",
    "        return 'UNDEFINED'\n",
    "\n",
    "user_input = 'show me the 5 biggest street_num, filter to where city is san francisco and use the location table'\n",
    "\n",
    "sql_or_nosql(user_input, login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing 5 rows from table 'courses':\n",
      "\n",
      "   CourseID                CourseName  InstructorID InstructorName  \\\n",
      "0       101           Data Structures             2      Dr. Brown   \n",
      "1       102                  Calculus             3      Dr. Smith   \n",
      "2       103          Database Systems             2      Dr. Brown   \n",
      "3       104            Linear Algebra             3      Dr. Smith   \n",
      "4       105  Introduction to Business             4      Dr. White   \n",
      "\n",
      "   CreditHours  \n",
      "0            3  \n",
      "1            4  \n",
      "2            3  \n",
      "3            3  \n",
      "4            3  \n"
     ]
    }
   ],
   "source": [
    "# Show ten rows command for sql\n",
    "\n",
    "def show_table(n_rows, table, login_info):\n",
    "    try:\n",
    "        # Establish a database connection\n",
    "        connection = pymysql.connect(\n",
    "            host=login_info['endpoint'],\n",
    "            user=login_info['username'],\n",
    "            password=login_info['password'],\n",
    "            db=login_info['sql_database_name']\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Construct the SQL query\n",
    "        query = f\"SELECT * FROM {table} LIMIT {n_rows};\"\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "        # Display the data\n",
    "        if rows:\n",
    "            print(f\"\\nShowing {len(rows)} rows from table \\'{table}\\':\\n\")\n",
    "\n",
    "            # Attempt to use pandas for a pretty table display\n",
    "            try:\n",
    "                df = pd.DataFrame(rows, columns=column_names)\n",
    "                print(df)\n",
    "            except ImportError:\n",
    "                # Fallback to line-by-line print\n",
    "                print(f\"{' | '.join(column_names)}\")\n",
    "                print(\"-\" * 80)\n",
    "                for row in rows:\n",
    "                    print(\" | \".join(map(str, row)))\n",
    "        else:\n",
    "            print(f\"No data found in table `{table}`.\")\n",
    "        \n",
    "        connection.close()\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \n",
    "    \n",
    "    return\n",
    "\n",
    "show_table(5, 'courses', login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents found in collection `products`.\n"
     ]
    }
   ],
   "source": [
    "## Show n rows for mongodb\n",
    "\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def show_collection(n_docs, collection_name, login_info):\n",
    "\n",
    "    try:\n",
    "\n",
    "        mongo_username = login_info['mongo_username']\n",
    "        mongo_password = login_info['mongo_password']\n",
    "\n",
    "        connection_string = f'mongodb+srv://{mongo_username}:{mongo_password}@cluster0.tgu2d.mongodb.net/'\n",
    "\n",
    "        # Establish a MongoDB connection\n",
    "        client = pymongo.MongoClient(connection_string)\n",
    "        db = client['ChatDB']\n",
    "        collection = db[collection_name]\n",
    "\n",
    "        # Fetch the documents\n",
    "        documents = list(collection.find().limit(n_docs))\n",
    "\n",
    "        # Display the documents\n",
    "        if documents:\n",
    "            print(f\"\\nShowing {len(documents)} documents from collection `{collection_name}`:\")\n",
    "\n",
    "            for i, doc in enumerate(documents, start=1):\n",
    "                print(f\"{i}: {doc}\")\n",
    "        else:\n",
    "            print(f\"No documents found in collection `{collection_name}`.\")\n",
    "\n",
    "        # Close the connection\n",
    "        client.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "show_collection(5, 'products', login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['UW_std_course', 'UW_std_advisedBY', 'UW_std_taughtBy', 'UW_std_person'])\n",
      "UW_std_course {'name': '_id', 'type': 'ObjectId', 'primary_key': True, 'unique_values': []}\n",
      "UW_std_advisedBY {'name': '_id', 'type': 'ObjectId', 'primary_key': True, 'unique_values': []}\n",
      "UW_std_taughtBy {'name': '_id', 'type': 'ObjectId', 'primary_key': True, 'unique_values': []}\n",
      "UW_std_person {'name': '_id', 'type': 'ObjectId', 'primary_key': True, 'unique_values': []}\n"
     ]
    }
   ],
   "source": [
    "mdata = get_mongodb_metadata(login_info)\n",
    "print(mdata.keys())\n",
    "for k, v in mdata.items():\n",
    "    print(k, v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcols: ['_id', 'course_id', 'courseLevel']\n"
     ]
    }
   ],
   "source": [
    "assoc_tables = ['UW_std_course']\n",
    "user_list = user_input.replace(',', '').split()\n",
    "assoc_cols = []\n",
    "col_idx_mdata = []\n",
    "for i in range(len(assoc_tables)):\n",
    "    table_columns = []\n",
    "    for j in range(len(mdata[assoc_tables[i]])):\n",
    "        table_columns.append(mdata[assoc_tables[i]][j]['name'])\n",
    "\n",
    "    print('tcols:', table_columns)\n",
    "    for word in user_list:\n",
    "        if word in table_columns:\n",
    "            assoc_cols.append(word)\n",
    "            idx = table_columns.index(word)\n",
    "            col_idx_mdata.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GROUP BY', 'AGGREGATE'] show me average p_id, maximum p_id, minimum p_id, and count of all rows from UW_std_person grouped by hasPosition\n",
      "tcols: ['_id', 'p_id', 'professor', 'student', 'hasPosition', 'inPhase', 'yearsInProgram']\n",
      "['UW_std_person']\n",
      "GB: hasPosition\n",
      "AGG: ['MIN', '$p_id', 'MAX', '$p_id', 'AVG', '$p_id', 'SUM', 1]\n",
      "Executing MongoDB pipeline: [{'$project': {'p_id': 1, 'hasPosition': 1}}, {'$group': {'_id': '$hasPosition', 'min_p_id': {'$min': '$p_id'}, 'max_p_id': {'$max': '$p_id'}, 'avg_p_id': {'$avg': '$p_id'}, 'sum_1': {'$sum': 1}}}]\n",
      "+-------------+----------+----------+--------------------+-------+\n",
      "|     _id     | min_p_id | max_p_id |      avg_p_id      | sum_1 |\n",
      "+-------------+----------+----------+--------------------+-------+\n",
      "|   Faculty   |    5     |   415    |      215.025       |  40   |\n",
      "|      0      |    3     |   435    | 223.89823008849558 |  226  |\n",
      "| Faculty_adj |    7     |   349    |       145.0        |   6   |\n",
      "| Faculty_aff |   103    |   293    | 229.33333333333334 |   3   |\n",
      "| Faculty_eme |    22    |   375    | 231.33333333333334 |   3   |\n",
      "+-------------+----------+----------+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson.son import SON\n",
    "\n",
    "def execute_mongo_query(user_input, keywords, login_info):\n",
    "    user_list = user_input.translate(str.maketrans('', '', string.punctuation.replace('_', ''))).split()\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    connection_string = f'mongodb+srv://{login_info['mongo_username']}:{login_info['mongo_password']}@cluster0.tgu2d.mongodb.net/'\n",
    "    mdata = get_mongodb_metadata(login_info)\n",
    "    client = pymongo.MongoClient(connection_string)\n",
    "    db = client[login_info['mongo_database_name']]\n",
    "\n",
    "    collections = db.list_collection_names()\n",
    "\n",
    "    assoc_collections = [word for word in user_list if word in collections]\n",
    "    if not assoc_collections:\n",
    "        print(\"No matching collections found.\")\n",
    "        return\n",
    "\n",
    "    assoc_cols = []\n",
    "    col_idx_mdata = []\n",
    "    for i in range(len(assoc_collections)):\n",
    "        table_columns = []\n",
    "        for j in range(len(mdata[assoc_collections[i]])):\n",
    "            table_columns.append(mdata[assoc_collections[i]][j]['name'])\n",
    "\n",
    "        print('tcols:', table_columns)\n",
    "        for word in user_list:\n",
    "            if word in table_columns:\n",
    "                assoc_cols.append(word)\n",
    "                idx = table_columns.index(word)\n",
    "                col_idx_mdata.append(idx)\n",
    "\n",
    "    unique_vals = []\n",
    "    for i in assoc_collections:\n",
    "        for j in col_idx_mdata:\n",
    "            unique_vals += mdata[i][j]['unique_values']\n",
    "\n",
    "    unique_vals = [str(item) if isinstance(item, (int, float)) else item for item in unique_vals]\n",
    "\n",
    "    collection = db[assoc_collections[0]]\n",
    "\n",
    "    pipeline = []\n",
    "    print(assoc_collections)\n",
    "    # Handle WHERE conditions (filters)\n",
    "    if 'WHERE' in keywords:\n",
    "        match_stage = {}\n",
    "        for key, values in where_words.items():\n",
    "            for i, word in enumerate(user_list):\n",
    "                try:\n",
    "                    bigram = word + f' {user_list[i+1]}'\n",
    "                except:\n",
    "                    pass\n",
    "                if word.lower() in values:\n",
    "                    if user_list[i-1] in assoc_cols:\n",
    "                        field = user_list[i - 1]\n",
    "                    elif user_list[i-2] in assoc_cols:\n",
    "                        field = user_list[i - 2]\n",
    "                    if user_list[i+1] in unique_vals:\n",
    "                        value = user_list[i + 1]\n",
    "                    elif user_list[i+2] in unique_vals:\n",
    "                        value = user_list[i + 2]\n",
    "                    elif user_list[i+3] in unique_vals:\n",
    "                        value = user_list[i + 3]\n",
    "                    elif f'{user_list[i+1]} {user_list[i+2]}' in unique_vals:\n",
    "                        value = f'{user_list[i+1]} {user_list[i+2]}'\n",
    "                    elif f'{user_list[i+2]} {user_list[i+3]}' in unique_vals:\n",
    "                        value = f'{user_list[i+2]} {user_list[i+3]}'\n",
    "                    else:\n",
    "                        value = 100\n",
    "                    if key == 'LESS_THAN':\n",
    "                        match_stage[field] = {\"$lt\": value}\n",
    "                    elif key == 'GREATER_THAN':\n",
    "                        match_stage[field] = {\"$gt\": value}\n",
    "                    elif key == 'EQUAL_TO':\n",
    "                        match_stage[field] = value\n",
    "                    elif key == 'NOT_EQUAL_TO':\n",
    "                        match_stage[field] = {\"$ne\": value}\n",
    "        if match_stage:\n",
    "            pipeline.append({\"$match\": match_stage})\n",
    "        print(\"Match\", match_stage)\n",
    "    \n",
    "    if 'SELECT' in keywords or 'AGGREGATE' in keywords:\n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word + f' {user_list[i+1]}'\n",
    "            except:\n",
    "                pass\n",
    "            if bigram in all_cols:\n",
    "                projection = {\"_id\": 0}\n",
    "                break\n",
    "            elif assoc_cols:\n",
    "                projection = {col: 1 for col in assoc_cols}\n",
    "        pipeline.append({\"$project\": projection})   \n",
    "\n",
    "    # Handle GROUP BY\n",
    "    if 'GROUP BY' in keywords:\n",
    "        group_by_field = None\n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word + f' {user_list[i+1]}'\n",
    "            except:\n",
    "                pass\n",
    "            if bigram in group_words:\n",
    "                if user_list[i+1] in assoc_cols:\n",
    "                    group_by_field = user_list[i+1]\n",
    "                elif user_list[i+2] in assoc_cols:\n",
    "                    group_by_field = user_list[i+2]\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    group_by_field = user_list[i+3]\n",
    "            elif word in group_words:\n",
    "                if user_list[i+1] in assoc_cols:\n",
    "                    group_by_field = user_list[i+1]\n",
    "                elif user_list[i+2] in assoc_cols:\n",
    "                    group_by_field = user_list[i+2]\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    group_by_field = user_list[i+3]\n",
    "        print(\"GB:\", group_by_field)\n",
    "        processes = []\n",
    "\n",
    "        if 'AGGREGATE' in keywords:\n",
    "            for key, values in aggregate_words.items():\n",
    "                for i, word in enumerate(user_list):\n",
    "                    if word.lower() in values:\n",
    "                        processes.append(key)\n",
    "                        if user_list[i+1] in assoc_cols:\n",
    "                            processes.append(f'${user_list[i+1]}')\n",
    "                        elif user_list[i+2] in assoc_cols:\n",
    "                            processes.append(f'${user_list[i+2]}')\n",
    "\n",
    "        group_stage = {\n",
    "            \"$group\": {\n",
    "                \"_id\": f\"${group_by_field}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        processes = ['SUM' if item == 'COUNT' else item for item in processes]\n",
    "        if len(processes) % 2 == 1:\n",
    "            processes.append(1)\n",
    "        print(\"AGG:\", processes)\n",
    "\n",
    "        for i, item in enumerate(processes):\n",
    "            if item in aggregate_words.keys():\n",
    "                try:\n",
    "                    alias = f'{item.lower()}_{processes[i+1].replace('$', '')}'\n",
    "                except:\n",
    "                    alias = f'{item.lower()}_{processes[i+1]}'\n",
    "                try:\n",
    "                    int(processes[i+1])\n",
    "                    group_stage['$group'][alias] = {f'${item.lower()}': processes[i+1]}\n",
    "                except:\n",
    "                    group_stage['$group'][alias] = {f'${item.lower()}': f'{processes[i+1]}'}\n",
    "\n",
    "        pipeline.append(group_stage)\n",
    "        if not any('$project' in stage for stage in pipeline):\n",
    "            pipeline = [stage for stage in pipeline if '$project' not in stage]\n",
    "    \n",
    "    elif 'AGGREGATE' in keywords:\n",
    "        processes = []\n",
    "\n",
    "        for key, value in aggregate_words.items():\n",
    "            for i, word in enumerate(user_list):\n",
    "                if word in value:\n",
    "                    processes.append(key)\n",
    "                    if user_list[i+1] in assoc_cols:\n",
    "                        processes.append(user_list[i+1])\n",
    "                    elif user_list[i+2] in assoc_cols:\n",
    "                        processes.append(user_list[i+2])\n",
    "        \n",
    "        processes = ['SUM' if item == 'COUNT' else item for item in processes]\n",
    "        group_stage = {\n",
    "            \"$group\": {\n",
    "                \"_id\": None\n",
    "            }\n",
    "        }\n",
    "        if len(processes) % 2 == 1:\n",
    "            processes.append(1)\n",
    "        print(\"AGG:\", processes)\n",
    "\n",
    "        for i, item in enumerate(processes):\n",
    "            if item in aggregate_words.keys():\n",
    "                alias = f'{item.lower()}_{processes[i+1]}'\n",
    "                group_stage['$group'][alias] = {f'${item.lower()}': f'${processes[i+1]}'}\n",
    "\n",
    "        pipeline.append(group_stage)\n",
    "        if not any('$project' in stage for stage in pipeline):\n",
    "            pipeline = [stage for stage in pipeline if '$project' not in stage]\n",
    "\n",
    "    # Handle ORDER BY\n",
    "    if 'ORDER BY' in keywords:\n",
    "        sort_order = 1  # Default to ascending\n",
    "        for i, word in enumerate(user_list):\n",
    "            try:\n",
    "                bigram = word + f' {user_list[i+1]}'\n",
    "            except:\n",
    "                pass\n",
    "            if word in desc_words or bigram in desc_words:\n",
    "                sort_order = -1\n",
    "            if bigram in order_words:\n",
    "                if user_list[i+2] in assoc_cols:\n",
    "                    sort_field = user_list[i+2]\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    sort_field = user_list[i+3]\n",
    "            elif word in order_words:\n",
    "                if user_list[i+1] in assoc_cols:\n",
    "                    sort_field = user_list[i+1]\n",
    "                elif user_list[i+2] in assoc_cols:\n",
    "                    sort_field = user_list[i+2]\n",
    "                elif user_list[i+3] in assoc_cols:\n",
    "                    sort_field = user_list[i+3]\n",
    "\n",
    "        pipeline.append({\"$sort\": {sort_field: sort_order}})\n",
    "    \n",
    "    # Handle LIMIT\n",
    "    if 'LIMIT' in keywords:\n",
    "        for i, word in enumerate(user_list):\n",
    "            if word in limit_words:\n",
    "                try:\n",
    "                    pipeline.append({\"$limit\": int(user_list[i+1])})\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    pipeline.append({\"$limit\": int(user_list[i+2])})\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    pipeline.append({\"$limit\": int(user_list[i+3])})\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    pipeline.append({\"$limit\": int(user_list[i-1])})\n",
    "                except:\n",
    "                    if not any([True for stage in pipeline if '$limit' in stage]):\n",
    "                        pipeline.append({\"$limit\": 5})\n",
    "                \n",
    "\n",
    "\n",
    "    print(\"Executing MongoDB pipeline:\", pipeline)\n",
    "    try:\n",
    "        result = list(collection.aggregate(pipeline))\n",
    "        headers = result[0].keys()\n",
    "        data = [row.values() for row in result]\n",
    "        print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n",
    "    except Exception as e:\n",
    "        print(\"Error executing query:\", e)\n",
    "\n",
    "    client.close()\n",
    "\n",
    "user_input = 'Show all columns where the course_id is greater than 100 from UW_std_course only show 6'\n",
    "# user_input = 'Show all columns where inPhase is equal to Post_Quals from UW_std_person, only show 6 and by descending _id'\n",
    "# user_input = 'Show me the average p_id for each inPhase from UW_std_person and sort it by _id'\n",
    "user_input = 'show me the average p_id from UW_std_person where student equals 1'\n",
    "user_input = 'show me every column from UW_std_person'\n",
    "user_input = 'show me average p_id, maximum p_id, minimum p_id, and count of all rows from UW_std_person grouped by hasPosition'\n",
    "keywords = match_query_pattern(user_input)\n",
    "print(keywords, user_input)\n",
    "\n",
    "execute_mongo_query(user_input, keywords, login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------+--------------------+-------+\n",
      "|     _id     | min_p_id | max_p_id |      avg_p_id      | sum_1 |\n",
      "+-------------+----------+----------+--------------------+-------+\n",
      "| Faculty_aff |   103    |   293    | 229.33333333333334 |   3   |\n",
      "| Faculty_adj |    7     |   349    |       145.0        |   6   |\n",
      "| Faculty_eme |    22    |   375    | 231.33333333333334 |   3   |\n",
      "|      0      |    3     |   435    | 223.89823008849558 |  226  |\n",
      "|   Faculty   |    5     |   415    |      215.025       |  40   |\n",
      "+-------------+----------+----------+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "connection_string = f'mongodb+srv://{login_info['mongo_username']}:{login_info['mongo_password']}@cluster0.tgu2d.mongodb.net/'\n",
    "mdata = get_mongodb_metadata(login_info)\n",
    "client = pymongo.MongoClient(connection_string)\n",
    "db = client[login_info['mongo_database_name']]\n",
    "collection = db['UW_std_person']\n",
    "pipeline =  [{'$project': {'p_id': 1, 'hasPosition': 1}}, {'$group': {'_id': '$hasPosition', 'min_p_id': {'$min': '$p_id'}, 'max_p_id': {'$max': '$p_id'}, 'avg_p_id': {'$avg': '$p_id'}, 'sum_1': {'$sum': 1}}}]\n",
    "result = list(collection.aggregate(pipeline))\n",
    "headers = result[0].keys()\n",
    "data = [row.values() for row in result]\n",
    "print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['Find all students who have yearsInProgram equal to Year_12 years from UW_std_ person',\n",
    "           'Find all faculty members from UW_std_person',\n",
    "           'Find all students who have completed their qualifying exams from UW_std_person',\n",
    "           'Find all students who are currently in their first year of the program',\n",
    "           'Find all records from person where their inPhase is Post_Generals ',\n",
    "           'Find all students who have a faculty position (either \"Faculty_aff\", \"Faculty_eme\", etc.), and are in their third year',\n",
    "           'Find all students who are either in the \"Post_Generals\" or \"Post_Quals\" phase',\n",
    "           'Find all students who are in the program for less than 5 years',\n",
    "           'Find all students who are not in a faculty position',\n",
    "           \"Find all students who have the 'student' field marked as '1' and have been in the program for 8 years or more\",\n",
    "           'Find all students who have been in the program for more than 5 years',\n",
    "           \"Find all students or faculty members in a specific phase, say 'Post_Quals', who have been in the program for more than 10 years\",\n",
    "           \"Find all records where the person is either a student or a professor\",\n",
    "           \"Find all students who have a faculty position ('Faculty' type) and have been in the program for more than 5 years\",\n",
    "           \"Find all students who are in their last year of the program ('Year_12')\",\n",
    "           \"Find all students who are not in any faculty position ('hasPosition' field is '0' or 'Faculty_aff', etc.)\",\n",
    "           'Find all students who are in the \"Pre_Quals\" phase and have a faculty position']\n",
    "\n",
    "\n",
    "# for input in queries:\n",
    "#     input += ' limit 5'\n",
    "#     keywords = match_query_pattern(input)\n",
    "#     print(keywords, input)\n",
    "#     print(execute_mongo_query(input, keywords, login_info))\n",
    "#     print(execute_sql_query(input, keywords, login_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
