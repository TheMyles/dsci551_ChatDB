{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mmoln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mmoln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PATTERNS = {\n",
    "    \"EXAMPLE\": [\"example\", \"examples\"],\n",
    "    \"UPLOAD\": [\"upload\", \"add\"],\n",
    "    \"SELECT\": [\"select\", \"columns\", \"fields\", \"retrieve\", \"get\", \"show\"],\n",
    "    \"AGGREGATE\": ['many', 'sum', 'average', 'mean', 'count'],\n",
    "    \"GROUP BY\": [\"group by\", \"aggregate\", \"group\", 'grouping', 'each', 'total'],\n",
    "    \"HAVING\": [\"having\", \"condition\", \"filter\", 'over', 'under', 'less', 'greater'],\n",
    "    \"ORDER BY\": [\"order by\", \"sort\", \"ascending\", \"descending\"],\n",
    "    \"WHERE\": [\"where\", \"condition\", \"filter\", 'over', 'under', 'less', 'greater', 'who'],\n",
    "    \"JOIN\": [\"join\", \"merge\", \"combine\", \"foreign key\", \"on\"]\n",
    "}\n",
    "\n",
    "QUERY_PATTERNS = {\n",
    "    \"EXAMPLE\": [\"example\", \"examples\", \"sample\", \"instance\", \"demo\", \"case\"],\n",
    "    \"UPLOAD\": [\"upload\", \"add\", \"insert\", \"import\", \"save\", \"load\", \"store\"],\n",
    "    \"SELECT\": [\"select\", \"columns\", \"fields\", \"retrieve\", \"get\", \"show\", \"fetch\", \"extract\",\n",
    "               \"display\", \"list\", \"view\", \"pick\", \"choose\", \"read\", \"query\"],\n",
    "    \"AGGREGATE\": [\"many\", \"sum\", \"average\", \"mean\", \"count\", \"total\", \"maximum\", \"minimum\",\n",
    "                  \"min\", \"max\", \"avg\", \"median\", \"aggregate\", \"statistics\", \"metrics\"],\n",
    "    \"GROUP BY\": [\"group by\", \"aggregate\", \"group\", \"grouping\", \"each\", \"total\", \"categorize\",\n",
    "                 \"partition\", \"classify\", \"segment\", \"cluster\", \"bucket\"],\n",
    "    \"HAVING\": [\"having\", \"condition\", \"filter\", \"over\", \"under\", \"less\", \"greater\", \"limit\", 'more',\n",
    "               \"range\", \"restrict\", \"criteria\", \"threshold\", \"constraint\", \"above\", \"below\"],\n",
    "    \"ORDER BY\": [\"order by\", \"sort\", \"ascending\", \"descending\", \"rank\", \"arrange\", \"prioritize\",\n",
    "                 \"sequence\", \"order\", \"hierarchy\", \"top\", \"bottom\", \"sorted\"],\n",
    "    \"WHERE\": [\"where\", \"condition\", \"filter\", \"over\", \"under\", \"less\", \"greater\", \"who\",\n",
    "              \"which\", \"that\", \"criteria\", \"subset\", \"find\", \"limit\", \"restrict\", \"search\",\n",
    "              \"match\", \"query\", \"constraint\"],\n",
    "    \"JOIN\": [\"join\", \"merge\", \"combine\", \"foreign key\", \"on\", \"unite\", \"relate\", \"link\",\n",
    "             \"connect\", \"associate\", \"bridge\", \"union\", \"inner\", \"outer\", \"left\", \"right\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "example_inputs = [\n",
    "    \"Show me all the records in the employees table\",  # Select\n",
    "    \"Upload this data '../data/sql_data/students.csv'\",  # upload\n",
    "    \"Show me examples of sql queries\",  # example\n",
    "    \"Show me examples of sql queries using group by\",  # example group by\n",
    "    \"Get the details of employees who work in the Sales department\",  # Where\n",
    "    \"How many employees are there in the company\",  # Select count(*)\n",
    "    \"Show me the names and salaries of employees earning more than $50000\",  # Where\n",
    "    \"List all employees, sorted by their hire date in descending order\",  # Order by\n",
    "    \"Find the average salary of employees in the Engineering department\",  # Select Avg() where\n",
    "    \"How many employees are there in each department\",  # Group by\n",
    "    \"Show me the departments where the total salaries of employees exceed $100000\",  # Having\n",
    "    \"List the products where the average price is less than $50\"  # Having\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELECT', 'GROUP BY', 'HAVING', 'WHERE', 'JOIN']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_query_pattern(user_input):\n",
    "\n",
    "    tokens = word_tokenize(user_input.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Match tokens to query patterns\n",
    "    token_counts = Counter(filtered_tokens)\n",
    "    types = []\n",
    "    for query_type, keywords in QUERY_PATTERNS.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in user_input.lower() or any(k in filtered_tokens for k in keyword.split()):\n",
    "                if query_type not in types:\n",
    "                    types.append(query_type)\n",
    "            \n",
    "    for word in filtered_tokens:\n",
    "        if word in QUERY_PATTERNS.items():\n",
    "            pass\n",
    "\n",
    "    for query_type, keywords in QUERY_PATTERNS.items():\n",
    "        pass\n",
    "\n",
    "    return types\n",
    "\n",
    "query = \"Show me the total sales grouped by region with a condition on sales.\"\n",
    "\n",
    "match_query_pattern(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUP BY\n",
      "['find', 'average', 'salary', 'employees', 'department']\n"
     ]
    }
   ],
   "source": [
    "for query_type, keywords in QUERY_PATTERNS.items():\n",
    "    for word in filtered_tokens:\n",
    "        if word in keywords:\n",
    "            print(query_type)\n",
    "            print(filtered_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show', 'me', 'all', 'the', 'records', 'in', 'the', 'employees', 'table']\n",
      "['show', 'records', 'employees', 'table']\n",
      "['SELECT']\n",
      "['upload', 'this', 'data']\n",
      "['upload', 'data']\n",
      "['UPLOAD']\n",
      "['show', 'me', 'examples', 'of', 'sql', 'queries']\n",
      "['show', 'examples', 'sql', 'queries']\n",
      "['EXAMPLE', 'SELECT']\n",
      "['show', 'me', 'examples', 'of', 'sql', 'queries', 'using', 'group', 'by']\n",
      "['show', 'examples', 'sql', 'queries', 'using', 'group']\n",
      "['EXAMPLE', 'SELECT', 'GROUP BY']\n",
      "['get', 'the', 'details', 'of', 'employees', 'who', 'work', 'in', 'the', 'sales', 'department']\n",
      "['get', 'details', 'employees', 'work', 'sales', 'department']\n",
      "['SELECT', 'WHERE']\n",
      "['how', 'many', 'employees', 'are', 'there', 'in', 'the', 'company']\n",
      "['many', 'employees', 'company']\n",
      "['AGGREGATE']\n",
      "['show', 'me', 'the', 'names', 'and', 'salaries', 'of', 'employees', 'earning', 'more', 'than', '50000']\n",
      "['show', 'names', 'salaries', 'employees', 'earning', '50000']\n",
      "['SELECT', 'HAVING']\n",
      "['list', 'all', 'employees', 'sorted', 'by', 'their', 'hire', 'date', 'in', 'descending', 'order']\n",
      "['list', 'employees', 'sorted', 'hire', 'date', 'descending', 'order']\n",
      "['SELECT', 'ORDER BY']\n",
      "['find', 'the', 'average', 'salary', 'of', 'employees', 'in', 'the', 'engineering', 'department']\n",
      "['find', 'average', 'salary', 'employees', 'engineering', 'department']\n",
      "['AGGREGATE', 'WHERE']\n",
      "['how', 'many', 'employees', 'are', 'there', 'in', 'each', 'department']\n",
      "['many', 'employees', 'department']\n",
      "['AGGREGATE', 'GROUP BY']\n",
      "['show', 'me', 'the', 'departments', 'where', 'the', 'total', 'salaries', 'of', 'employees', 'exceed', '100000']\n",
      "['show', 'departments', 'total', 'salaries', 'employees', 'exceed', '100000']\n",
      "['SELECT', 'AGGREGATE', 'GROUP BY', 'WHERE']\n",
      "['list', 'the', 'products', 'where', 'the', 'average', 'price', 'is', 'less', 'than', '50']\n",
      "['list', 'products', 'average', 'price', 'less', '50']\n",
      "['SELECT', 'AGGREGATE', 'HAVING', 'WHERE']\n"
     ]
    }
   ],
   "source": [
    "for i in example_inputs:\n",
    "    tokens = word_tokenize(i.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    print(tokens)\n",
    "    print(filtered_tokens)\n",
    "    print(match_query_pattern(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mmoln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
